# Quick Start Guide

Get the Film Asset Management system running in 5 minutes!

## Prerequisites Check

Before starting, ensure you have:
- âœ“ Python 3.10 or higher
- âœ“ Node.js 18 or higher
- âœ“ 5GB free disk space
- âœ“ Internet connection (for downloading ML models)

Quick check:
```bash
python3 --version  # Should show 3.10+
node --version     # Should show 18+
npm --version      # Should be installed
```

## Step 1: Frontend Setup (30 seconds)

Open a terminal and run:

```bash
# Install dependencies
npm install

# Build to check for errors
npm run build
```

Expected output:
```
âœ“ built in 7.88s
```

## Step 2: Backend Setup (2-3 minutes)

Open a **new terminal** and run:

```bash
cd backend
chmod +x start_server.sh
./start_server.sh
```

This will:
1. Create Python virtual environment
2. Install all dependencies (this takes the longest)
3. Run system tests
4. Start the server

Expected final output:
```
========================================
Starting FastAPI server on port 8000...
========================================

INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8000
```

## Step 3: Start Frontend (30 seconds)

Return to your first terminal and run:

```bash
npm run dev
```

Expected output:
```
  VITE v5.4.8  ready in 1234 ms

  âžœ  Local:   http://localhost:5173/
  âžœ  Network: use --host to expose
```

## Step 4: Open in Browser

1. Open your browser
2. Go to: `http://localhost:5173`
3. You should see the Film Asset Manager interface

## Step 5: Test Upload (1 minute)

1. Click "Upload Video" button
2. Select a short video file (5-10 seconds recommended for first test)
3. Wait for processing (10-30 seconds)
4. See results:
   - Keyframes extracted
   - Clusters created
   - Some shots may appear in "Noise Bucket"

## Troubleshooting

### Backend won't start

**Error:** "python: command not found"
```bash
# Use python3 instead
python3 --version
```

**Error:** "No module named 'fastapi'"
```bash
# Make sure you're in the virtual environment
cd backend
source venv/bin/activate
pip install -r requirements.txt
```

### Frontend won't start

**Error:** "Port 5173 already in use"
```bash
# Kill the process
lsof -ti:5173 | xargs kill -9
# Then try again
npm run dev
```

### Can't upload video

**Issue:** Upload button doesn't work
- Check that backend is running on port 8000
- Open browser DevTools (F12) and check Console for errors
- Make sure video file is in a supported format (MP4, MOV, AVI)

## What's Happening Behind the Scenes?

When you upload a video, the system:

1. **Extracts Keyframes** (2-5s)
   - Analyzes video motion
   - Static shots: 1 keyframe
   - Dynamic shots: 3 keyframes

2. **Generates Embeddings** (3-10s)
   - Scene embeddings with CLIP
   - Face detection with MTCNN
   - Creates 512-dimensional vectors

3. **Clusters Shots** (<1s)
   - Groups similar scenes together
   - Uses ChromaDB vector search
   - Uncertain shots go to Noise Bucket

4. **Saves to Database**
   - Stores in Supabase
   - Ready for active learning

## Next Steps

Now that it's working, try:

1. **Upload more videos** - See how clustering improves
2. **Drag and drop** - Move shots from Noise Bucket to clusters
3. **Toggle views** - Switch between Scene and Character views
4. **Check the data** - Open Supabase dashboard to see stored data

## Understanding the UI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sidebar         Main Gallery          Noise Bucket â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Upload  â”‚     â”‚ Cluster 1    â”‚      â”‚ Shot 1   â”‚ â”‚
â”‚  â”‚        â”‚     â”‚  ðŸ“ 5 shots  â”‚      â”‚ Shot 2   â”‚ â”‚
â”‚  â”‚Scene   â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚ Shot 3   â”‚ â”‚
â”‚  â”‚Char    â”‚     â”‚ Cluster 2    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚        â”‚     â”‚  ðŸ“ 3 shots  â”‚      Drag shots   â”‚
â”‚  â”‚Refresh â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      to clusters  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Locations

While running, files are stored in:
```
backend/
â”œâ”€â”€ uploads/         # Original uploaded videos
â”œâ”€â”€ keyframes/       # Extracted keyframe images
â”œâ”€â”€ training_data/   # Human feedback logs
â””â”€â”€ chroma_db/       # Vector database
```

## Stopping the System

When done:

1. Frontend: Press `Ctrl+C` in the frontend terminal
2. Backend: Press `Ctrl+C` in the backend terminal

Data is saved in Supabase and ChromaDB, so you can restart later.

## System Requirements

**Minimum:**
- CPU: 2 cores
- RAM: 4GB
- Disk: 5GB free

**Recommended:**
- CPU: 4+ cores
- RAM: 8GB+
- Disk: 10GB+ free
- GPU: Optional but speeds up processing

## Performance Tips

**First video upload is slow** because:
- ML models are downloaded (~500MB)
- Models are loaded into memory
- Subsequent uploads are much faster

**Speed up processing:**
- Use shorter videos for testing
- Use videos with clear faces
- Ensure good internet connection (first run)
- Add more RAM if available

## Complete Feature List

Current features:
- âœ“ Video upload and processing
- âœ“ Dynamic keyframe extraction
- âœ“ Scene clustering
- âœ“ Character detection
- âœ“ Active learning (drag-and-drop)
- âœ“ Feedback logging
- âœ“ Database persistence
- âœ“ Real-time updates

## Getting Help

If you're stuck:
1. Check `TROUBLESHOOTING.md` for common issues
2. Review `API_EXAMPLES.md` for API usage
3. Read `TESTING.md` for validation steps
4. See `DEPLOYMENT.md` for production setup

## Success Checklist

You're all set if:
- âœ“ Frontend loads at http://localhost:5173
- âœ“ Backend responds at http://localhost:8000
- âœ“ You can upload a video
- âœ“ Keyframes are extracted
- âœ“ Clusters are created
- âœ“ You can drag shots to clusters

Congratulations! Your AI-powered film asset management system is running!
